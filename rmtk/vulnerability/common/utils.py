# -*- coding: utf-8 -*-
import os
import csv
import math
import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate, optimize, stats
from shapely.geometry import LineString, MultiPoint, Point

def read_capacity_curves(input_file):
    # This function reads one, or a set of capacity curves

    with open(input_file, 'rU') as f:
        data = csv.reader(f)
        for line in data:
            if line[0] == 'Vb-droof' and line[1] == 'TRUE':
                capacity_curves = read_Vbdroof_capacity_curves(data)
                break
            elif line[0] == 'Vb-dfloor' and line[1] == 'TRUE':
                capacity_curves = read_Vbdfloor_capacity_curves(data)
                break
            elif line[0] == 'Sd-Sa' and line[1] == 'TRUE':
                capacity_curves = read_SdSa_capacity_curves(data)
                break

    return capacity_curves

def read_Vbdfloor_capacity_curves(data):

    # This function reads Sd-Sa type of capacity curves
    idealised = []
    periods = []
    ground_heights = []
    regular_heights = []
    gammas = []
    no_storeys = []
    weights = []
    Vb = []
    d_floor = []
    d_roof = []
    id_floor = []

    for line in data:
        if line[0] == 'Idealised':
            idealised.append(line[1])
        if line[0] == 'Periods [s]':
            for value in line[1:]:
                if isNumber(value):
                    periods.append(float(value))
        if line[0] == 'Ground heights [m]':
            for value in line[1:]:
                if isNumber(value):
                    ground_heights.append(float(value))
        if line[0] == 'Regular heights [m]':
            for value in line[1:]:
                if isNumber(value):
                    regular_heights.append(float(value))
        if line[0] == 'Gamma participation factors':
            for value in line[1:]:
                if isNumber(value):
                    gammas.append(float(value))
        if line[0] == 'Number storeys':
            for value in line[1:]:
                if isNumber(value):
                    no_storeys.append(int(value))
        if line[0] == 'Weights':
            for value in line[1:]:
                if isNumber(value):
                    weights.append(float(value))
        if line[0][0:6] == 'dfloor':
            subd_floor = []
            for value in line[1:]:
                if isNumber(value):
                    subd_floor.append(float(value))
            id_floor.append(subd_floor)
            if len(id_floor) == no_storeys[-1]:
                d_floor.append(id_floor)
                d_roof.append(subd_floor)
                id_floor = []
        if line[0][0:2] == 'Vb' and isNumber(line[0][2]):
            subVb = []
            for value in line[1:]:
                if isNumber(value):
                    subVb.append(float(value))
            Vb.append(subVb)

    if not weights:
        weights = np.ones_like(periods)
    average_period = np.average(np.array(periods), weights = np.array(weights))

    # Store all the data in the dictionary
    capacity_curves = {'type': None, 'idealised': None, 'periods': None,
                       'mean_period': None, 'ground_heights': None,
                       'regular_heights': None, 'gamma': None,
                       'no_storeys': None, 'weight': None, 'dfloor': None,
                       'droof': None, 'Vb': None}

    capacity_curves['type'] = 'Vb-dfloor'
    capacity_curves[ 'idealised' ] = idealised[0]
    capacity_curves['periods'] = periods
    capacity_curves['mean_period'] = average_period
    capacity_curves['ground_heights'] = ground_heights
    capacity_curves['regular_heights'] = regular_heights
    capacity_curves['gamma'] = gammas
    capacity_curves['no_storeys'] = no_storeys
    capacity_curves['weights'] = weights
    capacity_curves['dfloor'] = d_floor
    capacity_curves['droof'] =  d_roof
    capacity_curves['Vb'] = Vb

    return capacity_curves

def read_Vbdroof_capacity_curves(data):

    # This function reads Vb-droof type of capacity curves
    idealised = []
    periods = []
    ground_heights = []
    regular_heights = []
    gammas = []
    no_storeys = []
    weights = []
    Vb = []
    d_roof = []

    for line in data:
        if line[0] == 'Idealised':
            idealised.append(line[1])
        if line[0] == 'Periods [s]':
            for value in line[1:]:
                if isNumber(value):
                    periods.append(float(value))
        if line[0] == 'Ground heights [m]':
            for value in line[1:]:
                if isNumber(value):
                    ground_heights.append(float(value))
        if line[0] == 'Regular heights [m]':
            for value in line[1:]:
                if isNumber(value):
                    regular_heights.append(float(value))
        if line[0] == 'Gamma participation factors':
            for value in line[1:]:
                if isNumber(value):
                    gammas.append(float(value))
        if line[0] == 'Number storeys':
            for value in line[1:]:
                if isNumber(value):
                    no_storeys.append(int(value))
        if line[0] == 'Weights':
            for value in line[1:]:
                if isNumber(value):
                    weights.append(float(value))
        if line[0][0:5] == 'droof':
            subd_roof = []
            for value in line[1:]:
                if isNumber(value):
                    subd_roof.append(float(value))
            d_roof.append(subd_roof)
        if line[0][0:2] == 'Vb' and isNumber(line[0][2]):
            subVb = []
            for value in line[1:]:
                if isNumber(value):
                    subVb.append(float(value))
            Vb.append(subVb)

    if not weights:
        weights = np.ones_like(periods)
    average_period = np.average(np.array(periods), weights = np.array(weights))

    # Store all the data in the dictionary
    capacity_curves = {'type': None, 'idealised': None, 'periods': None,
                       'ground_heights': None, 'regular_heights': None,
                       'gamma': None, 'no_storeys': None, 'weights': None,
                       'droof': None, 'Vb': None}

    capacity_curves['type'] = 'Vb-droof'
    capacity_curves[ 'idealised' ] = idealised[0]
    capacity_curves['periods'] = periods
    capacity_curves['mean_period'] = average_period
    capacity_curves['ground_heights'] = ground_heights
    capacity_curves['regular_heights'] = regular_heights
    capacity_curves['gamma'] = gammas
    capacity_curves['no_storeys'] = no_storeys
    capacity_curves['weights'] = weights
    capacity_curves['droof'] =  d_roof
    capacity_curves['Vb'] = Vb

    return capacity_curves

def read_SdSa_capacity_curves(data):

    # This function reads Sd-Sa type of capacity curves
    periods = []
    heights = []
    gammas = []
    Sdy = []
    Say = []
    Sd = []
    Sa = []

    for line in data:
        if line[0] == 'Periods [s]':
            for value in line[1:]:
                if isNumber(value):
                    periods.append(float(value))
        if line[0] == 'Heights [m]':
            for value in line[1:]:
                if isNumber(value):
                    heights.append(float(value))
        if line[0] == 'Gamma participation factors':
            for value in line[1:]:
                if isNumber(value):
                    gammas.append(float(value))
        if line[0] == 'Sdy [m]':
            for value in line[1:]:
                if isNumber(value):
                    Sdy.append(float(value))
        if line[0] == 'Say [g]':
            for value in line[1:]:
                if isNumber(value):
                    Say.append(float(value))
        if line[0][0:2] == 'Sd' and isNumber(line[0][2]):
            subSd = []
            for value in line[1:]:
                if isNumber(value):
                    subSd.append(float(value))
            Sd.append(subSd)
        if line[0][0:2] == 'Sa' and isNumber(line[0][2]):
            subSa = []
            for value in line[1:]:
                if isNumber(value):
                    subSa.append(float(value))
            Sa.append(subSa)

    # Store all the data in the dictionary
    capacity_curves = {'type': None, 'periods': None, 'heights': None,
        'gamma': None, 'Sdy': None, 'Say': None, 'Sd': None, 'Sa': None}

    capacity_curves['type'] = 'Sd-Sa'
    capacity_curves['periods'] = periods
    capacity_curves['heights'] = heights
    capacity_curves['gamma'] = gammas
    capacity_curves['Sdy'] = Sdy
    capacity_curves['Say'] = Say
    capacity_curves['Sd'] = Sd
    capacity_curves['Sa'] = Sa

    return capacity_curves

def save_capacity_curves(capacity_curves, filename):

    if capacity_curves['type'] == 'Sd-Sa':
        save_SdSa_capacity_curves(capacity_curves, filename)

def save_SdSa_capacity_curves(capacity_curves, filename):

    no_capacity_curves = len(capacity_curves['Sd'])
    output = open(filename, 'w')
    output.write('Vb-droof, FALSE\n')
    output.write('Vb-dfloor, FALSE\n')
    output.write('Sd-Sa, TRUE\n')
    periods = 'Periods [s]'
    heights = 'Heights [m]'
    gammas = 'Gamma participation factors'
    Sdy = 'Sdy [m]'
    Say = 'Say [g]'
    for icc in range(no_capacity_curves):
        if capacity_curves['periods'] !=  None:
            periods = periods + ',' + str(capacity_curves['periods'][icc])
        if capacity_curves['heights'] !=  None:
            heights = heights + ',' + str(capacity_curves['heights'][icc])
        if capacity_curves['gamma'] !=  None:
            gammas = gammas + ',' + str(capacity_curves['gamma'][icc])
        if capacity_curves['Sdy'] !=  None:
            Sdy = Sdy + ',' + str(capacity_curves['Sdy'][icc])
        if capacity_curves['Say'] !=  None:
            Say = Say + ',' + str(capacity_curves['Say'][icc])

    output.write(periods + '\n')
    output.write(heights + '\n')
    output.write(gammas + '\n')
    output.write(Sdy + '\n')
    output.write(Say + '\n')

    for icc in range(no_capacity_curves):
        Sd = 'Sd'+str(icc+1)+' [m]'
        Sa = 'Sa'+str(icc+1)+' [g]'
        for ivalue in range(len(capacity_curves['Sd'][icc])):
            Sd = Sd + ',' + str(capacity_curves['Sd'][icc][ivalue])
            Sa = Sa + ',' + str(capacity_curves['Sa'][icc][ivalue])
        output.write(Sd + '\n')
        output.write(Sa + '\n')

    output.close()

def plot_capacity_curves(capacity_curves):

    #This function plots the capacity curves
    if capacity_curves['type'] == 'Sd-Sa':
        no_capacity_curves = len(capacity_curves['Sa'])
        for icc in range(no_capacity_curves):
            Sa = capacity_curves['Sa'][icc]
            Sd = capacity_curves['Sd'][icc]
            plt.plot(Sd, Sa, color = 'g', linewidth = 2)
        plt.plot(Sd, Sa, color = 'g', linewidth = 2,
                 label = 'individual capacity curve')
        plt.xlabel('Spectral displacement [m]', fontsize = 10)
        plt.ylabel('Spectral acceleration [g]', fontsize = 10)

    elif capacity_curves['type'] == 'Vb-dfloor' or capacity_curves['type'] == 'Vb-droof':
        no_capacity_curves = len(capacity_curves['Vb'])
        for icc in range(no_capacity_curves):
            Vb = capacity_curves['Vb'][icc]
            droof = capacity_curves['droof'][icc]
            plt.plot(droof, Vb, color = 'b', linewidth = 2)
        plt.plot(droof, Vb, color = 'b', linewidth = 2,
                 label = 'individual capacity curve')
        plt.xlabel('Roof displacement [m]', fontsize = 10)
        plt.ylabel('Base shear [kN]', fontsize = 10)

    plt.suptitle('Capacity curves')
    plt.legend(loc = 'lower right', frameon = False)
    plt.show()

def plot_idealised_capacity(idealised_capacity, capacity_curves, idealised_type):
    #This function plots the capacity curves
    no_capacity_curves = len(capacity_curves['Vb'])
    if idealised_type  == 'bilinear':
        for icc in range(no_capacity_curves):
            Vb = capacity_curves['Vb'][icc]
            droof = capacity_curves['droof'][icc]
            Vb_idealised = [0, idealised_capacity[icc][2], idealised_capacity[icc][2]]
            droof_idealised = [0, idealised_capacity[icc][0], idealised_capacity[icc][1]]
            plt.plot(droof, Vb, color = 'g', linewidth = 2)
            plt.plot(droof_idealised, Vb_idealised, color = 'r', linewidth = 2)

        plt.plot(droof, Vb, color = 'g', linewidth = 2, label = 'capacity curve')
        plt.plot(droof_idealised, Vb_idealised, color = 'r', linewidth = 2,
                 label = 'idealised capacity curve')
        plt.xlabel('Roof displacement [m]', fontsize = 10)
        plt.ylabel('Base shear [kN]', fontsize = 10)

    else:
        for icc in range(no_capacity_curves):
            Vb = capacity_curves['Vb'][icc]
            droof = capacity_curves['droof'][icc]
            Vb_idealised = idealised_capacity[icc][4:]
            Vb_idealised.insert(0, 0)
            Vb_idealised.append(idealised_capacity[icc][-1])
            droof_idealised = idealised_capacity[icc][0:4]
            droof_idealised.insert(0, 0)
            plt.plot(droof, Vb, color = 'g', linewidth = 2)
            plt.plot(droof_idealised, Vb_idealised, color = 'r', linewidth = 2)

        plt.plot(droof, Vb, color = 'g', linewidth = 2, label = 'capacity curve')
        plt.plot(droof_idealised, Vb_idealised, color = 'r', linewidth = 2,
                 label = 'idealised capacity curve')
        plt.xlabel('Roof displacement [m]', fontsize = 10)
        plt.ylabel('Base shear [kN]', fontsize = 10)

    plt.suptitle('Capacity curves')
    plt.legend(loc = 'lower right', frameon = False)
    plt.show()

def read_gmrs(folder):

    #This function reads a set of ground motion records
    #and stores them in a dictionary
    time = []
    acc = []
    dt = []
    no_points = []
    name = []
    for f in os.listdir(folder):
        if f.endswith(".csv"):
            itime, iacc = read_gmr(folder, f)
            time.append(itime)
            acc.append(iacc)
            dt.append(itime[1] - itime[0])
            no_points.append(len(iacc))
            name.append(f)

    gmrs = {'time': None, 'acc': None, 'dt': None,
        'no_points': None, 'name': None}
    gmrs['time'] = time
    gmrs['acc'] = acc
    gmrs['dt'] = dt
    gmrs['no_points'] = no_points
    gmrs['name'] = name

    return gmrs

def read_gmr(folder, gmr):

    time, acc = [], []
    with open(folder + '/' + gmr) as f:
        for line in f.readlines():
            line = line.split(',')
            time.append(float(line[0]))
            acc.append(float(line[1])*9.81)

    return time, acc

def plot_response_spectra(gmrs, minT, maxT):

    no_gmrs = len(gmrs['time'])
    damping = 0.05
    T = np.linspace(minT, maxT, 50)
    plt.figure(figsize = (15, 5))
    for igmr in range(no_gmrs):
        acc = gmrs['acc'][igmr]
        time = gmrs['time'][igmr]
        spectrum = NigamJennings(time, acc, T, damping)
    #    spectrum = NewmarkBeta(time, acc, T, damping)

        plt.subplot(1, 3, 1)
        plt.plot(T, spectrum['Sa'], color = 'b', linewidth = 2)
        plt.subplot(1, 3, 2)
        plt.plot(T, spectrum['Sd'], color = 'g', linewidth = 2)
        plt.subplot(1, 3, 3)
        plt.plot(spectrum['Sd'], spectrum['Sa'], color = 'r', linewidth = 2)

    plt.subplot(1, 3, 1)
    plt.xlabel('Periods of vibration (sec)', fontsize = 10)
    plt.ylabel('Spectral acceleration (g)', fontsize = 10)
    plt.subplot(1, 3, 2)
    plt.xlabel('Periods of vibration (sec)', fontsize = 10)
    plt.ylabel('Spectral displacement (m)', fontsize = 10)
    plt.subplot(1, 3, 3)
    plt.xlabel('Spectral displacement (m)', fontsize = 10)
    plt.ylabel('Spectral acceleration (g)', fontsize = 10)
    plt.show()

def NewmarkBeta(time, acc, T, damping):

    u0 = 0
    v0 = 0
    dt = time[1]-time[0]
    no_acc = len(acc)
    no_T = len(T)
    M = 1
    Sd = np.zeros(no_T)
    Sa = np.zeros(no_T)
    u = np.zeros(no_acc)
    a = np.zeros(no_acc)
    v = np.zeros(no_acc)
    at = np.zeros(no_acc)

    for i in range(no_T):
        if T[i] == 0:
            Sd[i] = 0
            Sa[i] = max(abs(np.array(acc)))
        else:
            wn = 2*math.pi/T[i]
            C = damping*2*M*wn
            K = ((2*math.pi)/T[i])**2*M
            u[0] = u0
            v[0] = v0
            a[0] = -acc[0]-C*v[0]-K*u[0]
            at[0] = acc[0]+a[0]
            for j in range(no_acc-1):
                u[j+1] = u[j] + dt*v[j] + dt**2 / 2*a[j]
                a[j+1] = (1/(M+dt*0.5*C)) * (-M*acc[j+1] - K*u[j+1] - C*(v[j]+dt*0.5*a[j]))
                v[j+1] = v[j] + dt*(0.5*a[j] + 0.5*a[j+1])
                at[j+1] = acc[j+1] + a[j+1]

            Sd[i] = max(abs(u))
            Sa[i] = max(abs(at))/9.81

    spectrum = {'Sd': None, 'Sa': None}
    spectrum['Sd'] = Sd
    spectrum['Sa'] = Sa

    return spectrum

def isNumber(s):
    try:
        float(s)
        return True
    except ValueError:
        return False

def read_damage_model(input_file):

    damage_states = []
    type_damage_state = []
    distribution = []
    mean = []
    cov = []
    median = []
    dispersion = []

    with open(input_file) as f:
        data = f.readlines()
        line = data[0]
        line = line.strip().split(',')
        type_criteria = line[1]

    with open(input_file, 'rU') as f:
        data = [row for row in csv.reader(f)]
        if type_criteria == 'interstorey drift':
            damage_states = [row[0] for row in data[2:]]
            distribution = [row[1] for row in data[2:]]
            for icc in range(0, (len(data[0])-2)/2):
                submedian = []
                subdispersion = []
                for iline in data[2:]:
                    submedian.append(float(iline[icc*2+2]))
                    subdispersion.append(float(iline[icc*2+3]))
                median.append(submedian)
                dispersion.append(subdispersion)

            damage_model = {'type_criteria': None, 'damage_states': None,
                 'median': None, 'dispersion': None}
            damage_model['type_criteria'] = type_criteria
            damage_model['damage_states'] = damage_states
            damage_model['distribution'] = distribution
            damage_model['median'] = median
            damage_model['dispersion'] = dispersion

        else:
            for iline in range(len(data)-2):
                line = data[iline+2]
                damage_states.append(line[0])
                type_damage_state.append(line[1])
                distribution.append(line[2])
                if type_criteria == 'capacity curve dependent':
                    if isNumber(line[3]):
                        mean.append(float(line[3]))
                    else:
                        mean.append(line[4])
                    cov.append(float(line[4]))

                if type_criteria == 'strain dependent':
                    mean.append(extract_values_string(line[3]))
                    cov.append(extract_values_string(line[4]))


        damage_model = {'type_criteria': None, 'damage_states': None,
            'type_damage_state': None, 'mean': None, 'cov': None}
        damage_model['type_criteria'] = type_criteria
        damage_model['damage_states'] = damage_states
        damage_model['type_damage_state'] = type_damage_state
        damage_model['distribution'] = distribution
        damage_model['mean'] = mean
        damage_model['cov'] = cov

    return damage_model

def extract_values_string(string):

    string = string.split(' ')
    values = []
    if isNumber(string[0]):
        for value in string:
            values.append(float(value))

    return values

def define_limit_states(capacity_curves, icc, damage_model):

    no_damage_states = len(damage_model['damage_states'])
    limit_states = []
    if damage_model['type_criteria'] == 'capacity curve dependent':
        Sd = capacity_curves['Sd'][icc]
        Sa = capacity_curves['Sa'][icc]
        Sdy = capacity_curves['Sdy'][icc]
        Say = capacity_curves['Say'][icc]
        for ids in range(no_damage_states):
            type_damage_state = damage_model['type_damage_state'][ids]
            distribution = damage_model['distribution'][ids]
            mean = damage_model['mean'][ids]
            cov = damage_model['cov'][ids]
            limit_states.append(define_limit_state(Sd, Sa, Sdy, Say,
                                                   type_damage_state,
                                                   distribution, mean, cov))

    return limit_states

def define_limit_state(Sd, Sa, Sdy, Say, type_damage_state, distribution, mean, cov):
    #FIXME: calls to the function sample_value are missing arguments A and B
    if type_damage_state == 'Sdy':
        mean = Sdy
        limit_state = sample_value(distribution, mean, cov)

    elif type_damage_state == 'Sdu':
        mean = max(Sd)
        limit_state = sample_value(distribution, mean, cov)

    elif type_damage_state == 'fraction Sdy':
        mean = mean*Sdy
        limit_state = sample_value(distribution, mean, cov)

    elif type_damage_state == 'fraction Sdu':
        #FIXME: Sdu is not defined
        mean = mean*Sdu
        limit_state = sample_value(distribution, mean, cov)

    elif type_damage_state == 'mean Sdy Sdu':
        mean = (Sdy+max(Sd))/2
        limit_state = sample_value(distribution, mean, cov)

    elif isNumber(type_damage_state[0]):
        values = type_damage_state.split()
        weight1 = float(values[0])
        weight2 = float(values[2])
        mean = (weight1*Sdy + weight2*max(Sd))/(weight1+weight2)
        #FIXME: use float('inf') instead of inf
        limit_state = sample_value(distribution, mean, cov, 0, inf)

    return limit_state

def sample_value(distribution, mean, cov, A, B):

    if cov == 0:
        result = mean
    else:
        result = float('-inf')

        while result <=  A or result > B:
            if distribution == 'normal':
                result = stats.norm.rvs(mean, mean*cov)
            elif distribution == 'lognormal':
                variance = (mean*cov)**2.0
                mu = math.log(mean ** 2.0 / math.sqrt(variance + mean ** 2.0) )
                sigma = math.sqrt(math.log((variance / mean ** 2.0) + 1.0))
                result = stats.lognorm.rvs(sigma, scale = math.exp(mu))
            elif distribution == 'gamma':
                beta = (mean*cov)**2/mean
                alpha = mean/beta
                result = stats.gamma.rvs(alpha, scale = beta)

    return result

def find_intersection(list1, list2, plot_flag):

    line1 = []
    for i in range(len(list1[0])):
        line1.append([list1[0][i], list1[1][i]])

    line2 = []
    for i in range(len(list2[0])):
        line2.append([list2[0][i], list2[1][i]])

    curve1 = LineString(line1)
    curve2 = LineString(line2)
    intersection = curve1.intersection(curve2)

    Sdi = []
    Sai = []
    if not intersection.is_empty:
        if isinstance(intersection, Point):
            Sdi.append(intersection.x)
            Sai.append(intersection.y)
        elif isinstance(intersection, MultiPoint):
            for points in intersection:
                coords = points.coords
                for xy in coords:
                    Sdi.append(xy[0])
                    Sai.append(xy[1])

        if plot_flag:
            plt.plot(list1[0], list1[1], color = 'r', linewidth = 2)
            plt.plot(list2[0], list2[1], color = 'b', linewidth = 2)
            plt.xlabel('Spectral displacement', fontsize = 10)
            plt.ylabel('Spectral acceleration', fontsize = 10)
            plt.plot(Sdi, Sai, 'ro', color = 'y')
            plt.show()

    return Sdi, Sai

def spread(array, no_steps):

    result = np.zeros((len(array)-1)*no_steps+1)

    for i in range(len(array)-1):
        result[i*no_steps] = array[i]
        step = (array[i+1] - array[i]) / no_steps
        for j in range(no_steps):
            result[i*no_steps + j + 1] = array[i] + (j+1)*step

    result[-1] = array[-1]

    return result

def allocate_damage(igmr, PDM, disp, limitStates):

    no_ls = len(limitStates)
    PDM[igmr, 0] = PDM[igmr, 0]+1
    for ils in range(no_ls):
        if disp > limitStates[no_ls - ils - 1]:
            PDM[igmr, no_ls-ils] = PDM[igmr, no_ls-ils]+1
            PDM[igmr, 0] = PDM[igmr, 0]-1
            break

    return PDM

def residuals(coeffs, y, x):
    # TODO: this function seems incomplete - x not used, IMLs not defined
    res = y - stats.lognorm.cdf(IMLs, coeffs[1], scale = math.exp(coeffs[0]))

    return res

def calculate_imls(gmrs, T, damping):

    Sa = []
    Sd = []
    pga = []
    for igmr in range(len(gmrs['time'])):
        time = gmrs['time'][igmr]
        acc = gmrs['acc'][igmr]
        spectrum = NigamJennings(time, acc, [T], damping)
        Sa.append(spectrum['Sa'][0])
        Sd.append(spectrum['Sd'][0])
        pga.append(max(abs(np.array(acc))))

    return Sa, Sd, pga

def calculate_mean_fragility(gmrs, PDM, T, damping, IMT, damage_model, method):

    imls = calculate_imls(gmrs, T, damping)

    if IMT == 'Sa':
        imls = imls[0]
        IMT = 'Sa('+str(T)+')'
    elif IMT == 'Sd':
        imls = imls[1]
        IMT = 'Sd('+str(T)+')'
    elif IMT == 'PGA':
        imls = imls[2]

    data = []
    with open('PDM.txt') as f:
        raw_data = csv.reader(f)
        for line in raw_data:
            data.append(map(float, line))
    data = np.array(data)
    imls = data[:, 0]
    PDM = data[:, 1:6]

    no_assets = np.sum(PDM, axis = 1, dtype = float)
    cumPDM = np.fliplr(np.cumsum(np.fliplr(PDM), axis = 1))
    cumPDM = np.transpose(cumPDM)
    cumPDM = cumPDM/no_assets

    logmeans = []
    logstddev = []
    for iDS in range(len(damage_model['damage_states'])):
        if method == 'least squares':
            solution, flag = optimize.leastsq(residual_lognormal_dist,
                                              [0.1, 0.6],
                                              args = (imls, cumPDM[iDS+1]))
            logmeans.append(solution[0])
            logstddev.append(solution[1])

    fragility_model = {'damage_states': None, 'logmean': None,
                       'logstddev': None, 'IMT': None}
    fragility_model['damage_states'] = damage_model['damage_states']
    fragility_model['logmean'] = logmeans
    fragility_model['logstddev'] = logstddev
    fragility_model['IMT'] = IMT

    return fragility_model

def save_mean_fragility(taxonomy, fragility_model, minIML, maxIML, output_type):

    damage_states = fragility_model['damage_states']
    logmeans = fragility_model['logmean']
    logstddev = fragility_model['logstddev']
    IMT = fragility_model['IMT']

    if output_type == 'csv':
        save_mean_fragility_csv(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT)
    if output_type == 'nrml':
        save_mean_fragility_nrml(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT)

def save_mean_fragility_csv(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT):

    with open(taxonomy+'.csv', 'wb') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([taxonomy, IMT, minIML, maxIML])
        writer.writerow(['Damage state', 'log mean', 'log stddev', 'mean', 'stddev', 'median', 'cov'])
        for iDS in range(len(damage_states)):
            mu = logmeans[iDS]
            sigma = logstddev[iDS]
            mean = math.exp(mu+sigma**2/2)
            stddev = math.sqrt(math.exp(2*mu+sigma**2)*(math.exp(sigma**2)-1))
            median = math.exp(mu)
            cov = abs(stddev/mean)
            writer.writerow([damage_states[iDS], mu, sigma, mean, stddev, median, cov])

def get_damage_states(csv_data):
    damage_states = []
    csv_data.next()
    csv_data.next()
    for line in csv_data:
        damage_states.append(line[0])
    return damage_states

def save_fragility_set_nrml(folder, destination_file):
    path = os.path.abspath(folder)
    destination_file = os.path.join(path, destination_file)
    nrml_file = open(destination_file, 'w')
    nrml_file.write('<?xml version="1.0" encoding="UTF-8"?>\n')
    nrml_file.write('<nrml xmlns="http://openquake.org/xmlns/nrml/0.5">\n\n')
    nrml_file.write('<fragilityModel assetCategory="buildings">\n\n')
    nrml_file.write('  <description>fragility model</description>\n')
    ds_str = '  <limitStates>'

    file_index = 0
    for f in os.listdir(folder):
        if f.endswith(".csv"):
            with open(os.path.join(path, f), 'rU') as fr:
                data = csv.reader(fr)
                if file_index == 0:
                    damage_states = get_damage_states(data)
                    fr.seek(0)
                    ds_str += ' '.join(damage_states)
                    nrml_file.write(ds_str + '</limitStates>\n\n')
                    file_index += 1
                taxonomy, IMT, minIML, maxIML = data.next()[0:4]
                data.next()

                if IMT == 'PGA' or IMT[:2] == 'Sa':
                    IMT_units = 'g'
                else:
                    IMT_units = 'm'

                nrml_file.write('  <fragilityFunction format="continuous" id="' + taxonomy + '">\n')
                nrml_file.write('    <imls imt="'+IMT+'" minIML="'+minIML+'" maxIML="'+maxIML+'"/>\n')

                for line in data:
                    ds, logmean, logstd, mean, stddev, median, cov = line[0:7]
                    nrml_file.write('    <params ls="'+ds+'" mean="'+mean+'" stddev="'+stddev+'"/>\n')
                nrml_file.write('  </fragilityFunction>\n\n')

    nrml_file.write('</fragilityModel>\n\n')
    nrml_file.write('</nrml>\n')
    nrml_file.close()

def save_mean_fragility_nrml(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT):

    nrml_file = open(taxonomy+'_fra.xml', 'w')
    nrml_file.write('<?xml version = "1.0" encoding = "UTF-8"?>\n')
    nrml_file.write('<nrml xmlns = "http://openquake.org/xmlns/nrml/0.4">\n')
    nrml_file.write('<fragilityModel format = "continuous">\n')
    nrml_file.write('   <description>fragility model for '+ taxonomy +'</description>\n')
    ds_str = ' <limitStates>'
    for damage_state in damage_states:
        ds_str = ds_str + ' ' + damage_state
    nrml_file.write(ds_str + '</limitStates>\n')
    nrml_file.close()

    save_single_fragility_nrml(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT)

    nrml_file = open(taxonomy+'_fra.xml', 'a')
    nrml_file.write('   </fragilityModel>\n')
    nrml_file.write('</nrml>\n')
    nrml_file.close()

def save_single_fragility_nrml(taxonomy, damage_states, logmeans, logstddev, minIML, maxIML, IMT):

    if IMT == 'PGA' or IMT[:2] == 'Sa':
        IMT_units = 'g'
    else:
        IMT_units = 'm'

    nrml_file = open(taxonomy+'_fra.xml', 'a')
    nrml_file.write('       <ffs type = "lognormal">\n')
    nrml_file.write('       <taxonomy>'+taxonomy+'</taxonomy>\n')
    nrml_file.write('       <IML IMT = "'+IMT+'" imlUnit = "'+IMT_units+'" minIML = "'+str(minIML)+'" maxIML = "'+str(maxIML)+'"/>\n')

    for iDS in range(len(damage_states)):
        mu = logmeans[iDS]
        sigma = logstddev[iDS]
        mean = math.exp(mu+sigma**2/2)
        stddev = math.sqrt(math.exp(2*mu+sigma**2)*(math.exp(sigma**2)-1))
        nrml_file.write('       <ffc ls = "'+damage_states[iDS]+'">\n')
        nrml_file.write('           <params mean = "'+str(mean)+'" stddev = "'+str(stddev)+'"/>\n')
        nrml_file.write('       </ffc>\n')
    nrml_file.write('       </ffs>\n')
    nrml_file.close()

def plot_fragility_model(fragility_model, minIML, maxIML):

    imls = np.linspace(minIML, maxIML, 100)
    color_scheme = ['g', 'b', 'y', 'orangered', 'r', 'k', 'm', 'c', '0.5', '0.75']
    for iDS in range(len(fragility_model['damage_states'])):
        mu = fragility_model['logmean'][iDS]
        sigma = fragility_model['logstddev'][iDS]
        plt.plot(imls, stats.lognorm.cdf(imls, sigma,
                                         scale=math.exp(mu)),
                                         color=color_scheme[iDS],
                                         linewidth=2,
                                         label= fragility_model['damage_states'][iDS])
        plt.legend(loc=4)
    plt.show()


def create_fragility_out_files(fragility_model, output_type, save):
    if save:
        path = '../../../../../../rmtk_data/output'
        out2 = 'fragility_output.csv'
        out_file = open(os.path.join(path, out2), 'w')
        [fragility_model_converted, outputs] = output_conversions(fragility_model, output_type)
        out_file.write('Damage State, %s, %s \n' %(outputs[0], outputs[1]))
        for iDS in range(len(fragility_model)):
            out_file.write('%s, %f, %f \n' %(fragility_model_converted[iDS][1], fragility_model_converted[iDS][0][0], fragility_model_converted[iDS][0][1]))
        out_file.close()

def output_conversions(fragility_model, output_type):
    fragility_model_converted = []

    if output_type == 'median-dispersion':
        for iDS in range(len(fragility_model)):
            median = np.exp(fragility_model[iDS][0][0])
            sigma = fragility_model[iDS][0][1]
            fragility_model_converted.append([[median, sigma], fragility_model[iDS][1]])

        outputs = ['median', 'dispersion']

    elif output_type == 'logmean-cov':
        for iDS in range(len(fragility_model)):
            sigma = fragility_model[iDS][0][1]
            median = np.exp(fragility_model[iDS][0][0])
            log_mean = median*np.exp(np.power(sigma, 2)/2)
            log_st_dev = np.sqrt((np.exp(np.power(sigma, 2))-1)*np.exp(2*np.log(median)+np.power(sigma, 2)))
            cov = log_st_dev/log_mean
            fragility_model_converted.append([[log_mean, cov], fragility_model[iDS][1]])

        outputs = ['mean of x', 'cov of x']

    elif output_type == 'mean-sigma':
        fragility_model_converted = fragility_model
        outputs = ['mean of ln(x)', 'st. dev. of ln(x)']

    return [fragility_model_converted, outputs]

#def plot_fragility(fragility_model, minIML, maxIML):
#
#    imls = np.linspace(minIML, maxIML, 100)
#    txt = []
#    colours = ['y', 'g', 'c', 'b', 'r', 'm', 'k']
#    for iDS in range(0, len(fragility_model[0])):
#        mu = fragility_model[0][iDS]
#        sigma = fragility_model[1][iDS]
#        txt.append('DS '+str(iDS+1))
#        if sigma <=  0:
#            y = np.zeros_like(imls)
#            y[imls>np.exp(mu)] = 1
#        else:
#            y = norm(mu, sigma).cdf(np.log(imls))
#            plt.plot(imls, y, color = colours[iDS], linewidth = 2)
#
#    plt.xlabel('Spectral acceleration at T elastic, Sa(Tel) [g]', fontsize = 12)
#    plt.ylabel('Probabilty of Exceedance', fontsize = 12)
#    plt.suptitle('Fragility Curves', fontsize = 12)
#    plt.show()

def NigamJennings(time, acc, periods, damping):

    add_PGA = False
    if periods[0] == 0:
        periods = np.delete(periods, 0)
        add_PGA = True

    dt = time[1]-time[0]
    num_steps = len(acc)
    num_per = len(periods)
    vel, disp = calculate_velocity_displacement(time, acc)
    omega = (2. * np.pi) / np.array(periods)
    omega2 = omega ** 2.
    omega3 = omega ** 3.
    omega_d = omega * math.sqrt(1.0 - (damping ** 2.))
    const = {'f1': (2.0 * damping) / (omega3 * dt),
            'f2': 1.0 / omega2,
            'f3': damping * omega,
            'f4': 1.0 / omega_d}
    const['f5'] = const['f3'] * const['f4']
    const['f6'] = 2.0 * const['f3']
    const['e'] = np.exp(-const['f3'] * dt)
    const['s'] = np.sin(omega_d * dt)
    const['c'] = np.cos(omega_d * dt)
    const['g1'] = const['e'] * const['s']
    const['g2'] = const['e'] * const['c']
    const['h1'] = (omega_d * const['g2']) - (const['f3'] * const['g1'])
    const['h2'] = (omega_d * const['g1']) + (const['f3'] * const['g2'])
    x_a, x_v, x_d = calculate_time_series(num_steps, num_per, time, acc, const, omega2)

    spectrum = {'Sa': None, 'Sv': None, 'Sd': None, 'T': None}
    spectrum['Sa'] = np.max(np.fabs(x_a)/9.81, axis = 0)
    spectrum['Sv'] = np.max(np.fabs(x_v), axis = 0)
    spectrum['Sd'] = np.max(np.fabs(x_d), axis = 0)
    spectrum['T'] = periods

    if add_PGA:
        spectrum = add_PGA_spectrum(spectrum, acc)

    return spectrum

def add_PGA_spectrum(spectrum, acc):

    spectrum['Sa'] = np.append(np.max(np.fabs(acc)/9.81), spectrum['Sa'])
    spectrum['Sv'] = np.append(0, spectrum['Sv'])
    spectrum['Sd'] = np.append(0, spectrum['Sd'])
    spectrum['T'] = np.append(0, spectrum['T'])

    return spectrum

def calculate_time_series(num_steps, num_per, time, acc, const, omega2):
    """
    Calculates the acceleration, velocity and displacement time series for
    the SDOF oscillator
    :param dict const:
        Constants of the algorithm
    :param np.ndarray omega2:
        Square of the oscillator period
    :returns:
        x_a = Acceleration time series
        x_v = Velocity time series
        x_d = Displacement time series
    """
    dt = time[1]-time[0]
    x_d = np.zeros([num_steps - 1, num_per], dtype = float)
    x_v = np.zeros_like(x_d)
    x_a = np.zeros_like(x_d)

    for k in range(0, num_steps - 1):
        yval = k - 1
        dug = acc[k + 1] - acc[k]
        z_1 = const['f2'] * dug
        z_2 = const['f2'] * acc[k]
        z_3 = const['f1'] * dug
        z_4 = z_1 / dt
        if k == 0:
            b_val = z_2 - z_3
            a_val = (const['f5'] * b_val) + (const['f4'] * z_4)
        else:
            b_val = x_d[k - 1, :] + z_2 - z_3
            a_val = (const['f4'] * x_v[k - 1, :]) +\
                (const['f5'] * b_val) + (const['f4'] * z_4)

        x_d[k, :] = (a_val * const['g1']) + (b_val * const['g2']) +\
            z_3 - z_2 - z_1
        x_v[k, :] = (a_val * const['h1']) - (b_val * const['h2']) - z_4
        x_a[k, :] = (-const['f6'] * x_v[k, :]) - (omega2 * x_d[k, :])

    return x_a, x_v, x_d

def calculate_velocity_displacement(time, acc):
    '''
    Returns the velocity and displacment time series using simple integration
    :param float time_step:
        Time-series time-step (s)
    :param np.ndarray acceleration:
        Acceleration time-history
    :returns:
        velocity - Velocity Time series (cm/s)
        displacement - Displacement Time series (cm)
    '''
    dt = time[1]-time[0]
    velocity = dt * integrate.cumtrapz(acc, initial = 0.)
    displacement = dt * integrate.cumtrapz(velocity, initial = 0.)
    return velocity, displacement

def residual_lognormal_dist(coeffs, imls, fractions):

    mu = coeffs[0]
    sigma = coeffs[1]
    residual = abs(np.array(fractions) - stats.lognorm.cdf(imls, sigma, scale = math.exp(mu)))

    return residual

def add_information(capacity_curves, attribute, type, data):
    #FIXME: type is a reserved keyword, change to something else
    no_capacity_curves = len(capacity_curves['Sa'])

    if attribute == 'heights' or attribute == 'periods' or attribute == 'gamma':
        if type == 'value':
            values = []
            for icc in range(no_capacity_curves):
                values.append(data)
            capacity_curves[attribute] = values
        elif type == 'vector':
            capacity_curves[attribute] = data
        elif type == 'calculate' and attribute == 'periods':
            periods = []
            for icc in range(no_capacity_curves):
                Sd = capacity_curves['Sd'][icc][data]
                Sa = capacity_curves['Sa'][icc][data]
                periods.append(2*math.pi*math.sqrt(Sd/(Sa*9.81)))
            capacity_curves[attribute] = periods

    elif attribute == 'yielding point':
        Sdy = []
        Say = []
        for icc in range(no_capacity_curves):
            Sdy.append(capacity_curves['Sd'][icc][data])
            Say.append(capacity_curves['Sa'][icc][data])
        capacity_curves['Sdy'] = Sdy
        capacity_curves['Say'] = Say
    else:
        print attribute + ' is not a recognized attribute. No information was added.'

    return capacity_curves


def idealisation(typ, capacity_curves):
    idealised_capacity = []
    no_capacity_curves = len(capacity_curves['Vb'])
    for icc in range(no_capacity_curves):
        droof = capacity_curves['droof'][icc]
        Vb = capacity_curves['Vb'][icc]
        if typ == 'bilinear':
            idealised_capacity.append(bilinear(droof, Vb, capacity_curves['idealised']))
        elif typ == 'quadrilinear':
            idealised_capacity.append(quadrilinear(droof, Vb, capacity_curves['idealised']))

    return idealised_capacity

def bilinear(droof, Vb, idealised):
#   FEMA method
    if idealised == 'FALSE':
        droof = np.array(droof)
        Fy = np.max(Vb)
        du = np.max(droof)
        for index, item in enumerate(Vb):
            if item >=  Fy:
                break
        Ay = 0.6*Fy
        Ax = np.interp(Ay, Vb[0:index], droof[0:index])
        slp = Ay/Ax
        dy = Fy/slp
    else:
        dy = droof[1]
        du = droof[2]
        Fy = Vb[1]

    return [dy, du, Fy]

def quadrilinear(droof, Vb, idealised):
    if idealised == 'FALSE':
        droof = np.array(droof)
        Fmax = np.max(Vb)
        for index, item in enumerate(Vb):
            if item >=  Fmax:
                break
        fmax = index
        dmax = droof[index]

    #   Yielding point:
    #   Vulnerability guidelines method
    #   Find yielding displacement with equal energy principle n the interval from 0 to Dmax
        Areas = np.array([(Vb[i+1]+Vb[i])/2 for i in range(0, fmax)])
        dd = np.array([droof[i+1]-droof[i] for i in range(0, fmax)])
        Edmax = np.sum(dd*Areas) #Area under the pushover curve in the interval from 0 to Dmax
        dy = 2*(dmax-Edmax/Fmax)
        Fy = Fmax

        #   Onset of plateu
        #   Find were slope of pushover curve before decreasing in the plateu
        Vb_norm = Vb[fmax::]/Fy
        d_norm = droof[fmax::]/dy
        slp = [(Vb_norm[i]-Vb_norm[i-1])/(d_norm[i]-d_norm[i-1]) for i in xrange(1, len(Vb_norm))]
        indy_soft = np.nonzero(abs(np.array(slp))>0.3)
        if len(indy_soft[0])>1:
            fmin = indy_soft[0][-1]+fmax
            Fmin = Vb[fmin]
            dmin = droof[fmin]
                #   Onset of softening
            #   Find yielding displacement with equal energy principle n the interval from Dmax to Dmin (onset of plateu)
            Areas = np.array([(Vb[i+1]+Vb[i])/2 for i in range(fmax, fmin)])
            dd = np.array([droof[i+1]-droof[i] for i in range(fmax, fmin)])
            Edmin = np.sum(dd*Areas)
            ds = 2/(Fmax-Fmin)*(Edmin - (dmin-dmax)*Fmax + 0.5*dmin*(Fmax-Fmin))
            du = np.max(droof)
            if ds<dy: ds = dy
            if ds>du: ds = du
            #   Residual Plateu
            if len(indy_soft[0])>0:
                Areas =  np.array([(Vb[i+1]+Vb[i])/2 for i in range(fmin, len(Vb)-1)])
                dd = np.array([droof[i+1]-droof[i] for i in range(fmin, len(Vb)-1)])
                Edplat = np.sum(dd*Areas)
                Fres = Edplat/(droof[-1]-dmin)
                slp_soft = abs((Fmax-Fmin)/(ds-dmin))
                dmin = dmin+(Fmin-Fres)/slp_soft
                if dmin>du:
                    dmin = du
                    Fmin = Vb[-1]
                else:
                    Fmin = Fres
        else:
            fmin = len(Vb)-1
            Fmin = Fmax
            dmin = droof[fmin]
            ds = dmin
            du = dmin
    else:
        dy = droof[1]
        ds = droof[2]
        dmin = droof[3]
        du = droof[4]
        Fy = Vb[1]
        Fmax = Vb [2]
        Fmin = Vb[3]

    return [dy, ds, dmin, du, Fy, Fmax, Fmin]

def InterStoreyDrift_disp(capacity_curves, icc):
    #convert displacement to inter-storey-drift
    no_storeys = capacity_curves['no_storeys'][icc]
    H_ground = capacity_curves['ground_heights'][icc]
    H_up = capacity_curves['regular_heights'][icc]
    H_tot = H_ground + H_up*(no_storeys-1)

    if capacity_curves['type'] == 'Vb-dfloor':
        disp = capacity_curves['dfloor'][icc]
        H = np.zeros(no_storeys+2)
        H[0] = 0
        H[1] = H_ground
        H[2:] = H_up*np.ones(no_storeys)

        disp.insert(0, np.zeros_like(disp[0]))
        a = np.zeros_like(disp)
        for i in range(0, no_storeys):
            a[i] = np.divide(np.array(disp[i+1])-np.array(disp[i]), H[i+1]) #convert displacement to inter-storey-drift

        ISDvec = np.max(a, axis = 0)
        RDvec = np.array(capacity_curves['droof'][icc])

    else:
        # This is a simple assumption on the relationship between roof displacement and drift
        RDvec = np.array(capacity_curves['droof'][icc])
        ISDvec = np.array(RDvec)/H_tot

    return [ISDvec, RDvec]

def get_spectral_ratios(capacity_curves, input_spectrum):

    Tuni = capacity_curves['mean_period']
    T = capacity_curves['periods']

    with open(input_spectrum, 'rb') as f:
        data = f.read()
        l = data.rstrip()
        lines = l.split('\n')
        data = [lines[i].split('\t') for i in range(0, len(lines))]
        Ts = np.array([float(ele[0]) for ele in data])
        Sa = np.array([float(ele[1]) for ele in data])
        S_Tuni = np.interp(Tuni, Ts, Sa)
        S_T = np.array([np.interp(ele, Ts, Sa) for ele in T])
        Sa_ratios = S_Tuni/S_T

    return Sa_ratios

def calculate_fragility_statistics(gmrs, PDM, T, damping, IMT, damage_model,
                                   method, no_samples, size_sample):

    #imls = calculate_imls(gmrs, T, damping)

    #if IMT == 'Sa':
    #    imls = imls[0]
    #elif IMT == 'Sd':
    #    imls = imls[1]
    #elif IMT == 'PGA':
    #    imls = imls[2]

    data = []
    with open('PDM.txt') as f:
        raw_data = csv.reader(f)
        for line in raw_data:
            data.append(map(float, line))
    data = np.array(data)
    imls = data[:, 0]
    PDM = data[:, 1:6]

    no_gmrs = len(imls)
    no_DS = len(damage_model['damage_states'])
    no_assets = np.sum(PDM, axis=1, dtype=float)
    cumPDM = np.fliplr(np.cumsum(np.fliplr(PDM), axis=1))
    cumPDM = np.transpose(cumPDM)
    cumPDM = cumPDM/no_assets

    statistics = []
    for isample in range(no_samples):
        sample_indices = np.random.random_integers(0, no_gmrs-1, size_sample)
        sample_imls = imls[sample_indices]
        sample_cumPDM = cumPDM[:, sample_indices]
        fragility_model = []
        for iDS in range(no_DS):
            if method == 'least squares':
                solution, flag = optimize.leastsq(residual_lognormal_dist,
                                                  [0.1, 0.6],
                                                  args=(sample_imls,
                                                        sample_cumPDM[iDS+1]))
                fragility_model.append(solution)
        statistics.append(np.reshape(fragility_model, 2*no_DS))

    statistics = np.array(statistics)
    means = np.mean(statistics, axis=0)
    stddev = np.std(statistics, axis=0)

    fragility_stats = {'damage_states': None, 'mean': None, 'stddev': None,
        'correlation': None, 'IMT': None}
    fragility_stats['damage_states'] = damage_model['damage_states']
    fragility_stats['mean'] = np.reshape(means, (no_DS, 2))
    fragility_stats['stddev'] = np.reshape(stddev, (no_DS, 2))
    fragility_stats['correlation'] = np.corrcoef(np.transpose(statistics))
    fragility_stats['statistics'] = statistics
    fragility_stats['IMT'] = IMT

    return fragility_stats

def plot_fragility_stats(fragility_stats, minIML, maxIML):

    imls = np.linspace(minIML, maxIML, 100)
    color_scheme = ['g', 'b', 'y', 'orangered', 'r', 'k', 'm', 'c', '0.5', '0.75']
    for iDS in range(len(fragility_stats['damage_states'])):
        mu = fragility_stats['mean'][iDS][0]
        sigma = fragility_stats['mean'][iDS][1]
        plt.plot(imls, stats.lognorm.cdf(imls, sigma, scale = math.exp(mu)),
                 color = color_scheme[iDS],  linewidth = 2,
                 label = fragility_stats['damage_states'][iDS])
        plt.legend(loc = 4)
    plt.show()

def read_consequence_model(input_file):

    damage_states, distribution, mean, cov, A, B = [], [], [], [], [], []
    with open(input_file, 'rU') as f:
        data = csv.reader(f)
        for iline, row in enumerate(data):
            if iline > 0:
                damage_states.append(row[0])
                distribution.append(row[1])
                mean.append(float(row[2]))
                cov.append(float(row[3]))
                A.append(float(row[4]))
                B.append(float(row[5]))

    cons_model = {'damage_states': None, 'distribution': None, 'mean': None,
        'cov': None, 'A': None, 'B': None}
    cons_model['damage_states'] = damage_states
    cons_model['distribution'] = distribution
    cons_model['mean'] = mean
    cons_model['cov'] = cov
    cons_model['A'] = A
    cons_model['B'] = B

    return cons_model

def convert_fragility_vulnerability(fragility_model, cons_model, imls, dist_type):

    vulnerability_model = []
    if check_damage_states(fragility_model, cons_model):
        no_samples = 100
        loss_ratios = []
        for isample in range(no_samples):
            loss_ratios.append(sample_loss_ratios(fragility_model, cons_model, imls))
    if dist_type == 'lognormal' or dist_type == 'beta':
        vulnerability_model = create_parametric_vul_model(imls, loss_ratios, dist_type, fragility_model['IMT'])
    elif dist_type == 'PMF':
        vulnerability_model = create_nonparametric_vul_model(imls, loss_ratios, dist_type, fragility_model['IMT'])

    else:
        print 'The fragility model and the consequence model are not compatible.'

    return vulnerability_model

def create_parametric_vul_model(imls, loss_ratios, dist_type, IMT):

    mean = np.mean(np.array(loss_ratios), axis = 0)
    stddev = np.std(np.array(loss_ratios), axis = 0)
    cov = np.zeros(len(mean))
    for icov in range(len(cov)):
        if mean[icov] > 0:
            if stddev[icov]/mean[icov] > 10**-4:
                cov[icov] = stddev[icov]/mean[icov]

    vulnerability_model = {'imls': None, 'distribution': None,
        'mean': None, 'cov': None, 'IMT': None}
    vulnerability_model['imls'] = imls
    vulnerability_model['distribution'] = dist_type
    vulnerability_model['mean'] = mean
    vulnerability_model['cov'] = cov
    vulnerability_model['IMT'] = IMT

    return vulnerability_model

def create_nonparametric_vul_model(imls, sampled_loss_ratios, dist_type, IMT):

    no_values = 20
    no_samples = len(sampled_loss_ratios)
    loss_ratios = np.linspace(0.0, 1.0, no_values)
    probs = np.zeros((no_values, len(imls)))

    for isample in range(no_samples):
        for iiml in range(len(imls)):
            if sample_loss_ratios[isample][iiml] == 0:
                probs[0][iiml] = probs[0][iiml] + 1
            elif sample_loss_ratios[isample][iiml] == 1:
                probs[-1][iiml] = probs[-1][iiml] + 1
            else:
                idx = (np.abs(loss_ratios[1:-1]-sample_loss_ratios[isample][iiml])).argmin()
                probs[idx+1][iiml] =  probs[idx+1][iiml] + 1

    probs = probs/no_samples
    vulnerability_model = {'imls': None, 'distribution': None,
        'loss_ratios': None, 'probabilities': None, 'IMT': None}
    vulnerability_model['imls'] = imls
    vulnerability_model['distribution'] = dist_type
    vulnerability_model['loss_ratios'] = loss_ratios
    vulnerability_model['probabilities'] = probs
    vulnerability_model['IMT'] = IMT

    return vulnerability_model

def plot_vulnerability_model(vulnerability_model, minIML, maxIML):

    imls = np.linspace(minIML, maxIML, 100)
    if vulnerability_model['distribution'] == 'lognormal':
        mean_lrs = vulnerability_model['mean']
        plt.plot(imls, mean_lrs, linewidth=2)
        plt.ylabel('Mean Loss Ratio', fontsize=12)
    elif vulnerability_model['distribution'] == 'beta':
        mean_lrs = vulnerability_model['mean']
        plt.plot(imls, mean_lrs, linewidth=2)
        plt.ylabel('Mean Loss Ratio', fontsize=12)
    elif vulnerability_model['distribution'] == 'PMF':
        imls = vulnerability_model['imls']
        lrs = vulnerability_model['loss_ratios']
        probs = vulnerability_model['probabilities']
        mean_lrs = np.dot(lrs, probs)
        imls.insert(0, 0)
        mean_lrs = np.insert(mean_lrs, 0, 0)
        print imls
        print mean_lrs
        plt.plot(imls, mean_lrs, linewidth=2)
        plt.ylabel('Mean Loss Ratio', fontsize=12)
    plt.xlabel('IMLs', fontsize=12)
    plt.suptitle('Vulnerability function', fontsize=16)
    plt.show()

def check_damage_states(model1, model2):

    result = True
    for iDS in range(len(model1['damage_states'])):
        if model1['damage_states'][iDS] !=  model2['damage_states'][iDS]:
            result = False

    return result

def sample_loss_ratios(fragility_model, cons_model, imls):

    no_damage_states = len(fragility_model['damage_states'])
    loss_ratios = np.zeros(len(imls))

    for iDS in range(no_damage_states):
        distribution = cons_model['distribution'][iDS]
        mean = cons_model['mean'][iDS]
        cov = cons_model['cov'][iDS]
        A = cons_model['A'][iDS]
        B = cons_model['B'][iDS]
        damage_ratio = sample_value(distribution, mean, cov, A, B)
        mu = fragility_model['logmean'][iDS]
        sigma = fragility_model['logstddev'][iDS]

        if iDS == no_damage_states-1:
            fraction = stats.lognorm.cdf(imls, sigma, scale = math.exp(mu))
        else:
            mu2 = fragility_model['logmean'][iDS]
            sigma2 = fragility_model['logstddev'][iDS]
            fraction = stats.lognorm.cdf(imls, sigma, scale = math.exp(mu))-stats.lognorm.cdf(imls, sigma2, scale = math.exp(mu2))
        loss_ratios = loss_ratios + fraction*damage_ratio

    return loss_ratios

def save_vulnerability(taxonomy, vulnerability_model, output_type):

    imls = vulnerability_model['imls']
    IMT = vulnerability_model['IMT']
    distribution = vulnerability_model['distribution']
    if distribution == 'lognormal' or distribution == 'beta':
        values1 = vulnerability_model['mean']
        values2 = vulnerability_model['cov']
    elif distribution == 'PMF':
        values1 = vulnerability_model['loss_ratios']
        values2 = vulnerability_model['probabilities']

    if output_type == 'csv':
        save_vulnerability_csv(taxonomy, imls, values1, values2, distribution, IMT)
    if output_type == 'nrml':
        save_vulnerability_nrml(taxonomy, imls, values1, values2, distribution, IMT)

def save_vulnerability_csv(taxonomy, imls, values1, values2, distribution, IMT):

    with open(taxonomy+'_vul.csv', 'wb') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([taxonomy, IMT, distribution])
        if distribution == 'lognormal' or distribution == 'beta':
            writer.writerow(np.append('imls', imls))
            writer.writerow(np.append('mean', values1))
            writer.writerow(np.append('cov', values2))

        elif distribution == 'PMF':
            writer.writerow(['loss ratio', 'probabilities'])
            for iLR in range(len(values1)):
                writer.writerow(np.append(values1[iLR], values2[iLR, :]))


def save_vulnerability_nrml(taxonomy, imls, values1, values2, distribution, IMT):

    nrml_file = open(taxonomy+'_vul.xml', 'w')
    nrml_file.write('<?xml version = "1.0" encoding = "utf-8"?>\n')
    nrml_file.write('<nrml xmlns = "http://openquake.org/xmlns/nrml/0.5">\n')
    nrml_file.write('<vulnerabilityModel id = "'+taxonomy+'" assetCategory = "buildings" lossCategory = "economic">\n')
    nrml_file.write('   <description>vulnerability model for '+ taxonomy +'</description>\n')
    nrml_file.close()

    save_single_vulnerability_nrml(taxonomy, imls, values1, values2, distribution, IMT)

    nrml_file = open(taxonomy+'_vul.xml', 'a')
    nrml_file.write('</vulnerabilityModel>\n')
    nrml_file.write('</nrml>\n')
    nrml_file.close()

def save_single_vulnerability_nrml(taxonomy, imls, values1, values2, distribution, IMT):

    imls_str = convert_array_to_string(imls)
    nrml_file = open(taxonomy+'_vul.xml', 'a')

    if distribution == 'lognormal':
        dist = 'LN'
    elif distribution == 'beta':
        dist = 'BT'
    elif distribution == 'PMF':
        dist = 'PM'

    nrml_file.write('       <vulnerabilityFunction id = "'
                    + taxonomy + '" dist = "' + dist + '">\n')

    if distribution == 'lognormal' or distribution == 'beta':
        print values1
        lrs_str = convert_array_to_string(values1)
        cov_str = convert_array_to_string(values2)
        nrml_file.write('       <imls imt = "'+IMT+'">'+imls_str+'</imls>\n')
        nrml_file.write('       <meanLRs>'+lrs_str+'</meanLRs>\n')
        nrml_file.write('       <covLRs>'+cov_str+'</covLRs>\n')

    elif distribution == 'PMF':
        for iLR in range(len(values1)):
            probs = convert_array_to_string(values2[iLR])
            nrml_file.write('       <probabilities lr = "'
                            + str(values1[iLR]) + '">' + probs
                            + '</probabilities>)\n')

    nrml_file.write('       </vulnerabilityFunction>\n')

def save_vulnerability_set_nrml(folder, destination_file):
    path = os.path.abspath(folder)
    destination_file = os.path.join(path, destination_file)
    nrml_file = open(destination_file, 'w')
    nrml_file.write('<?xml version="1.0" encoding="UTF-8"?>\n')
    nrml_file.write('<nrml xmlns="http://openquake.org/xmlns/nrml/0.5">\n\n')
    nrml_file.write('<vulnerabilityModel assetCategory="buildings" lossCategory="economic">\n')
    nrml_file.write('  <description>vulnerability model</description>\n\n')

    for f in os.listdir(folder):
        if f.endswith(".csv"):
            with open(os.path.join(path, f), 'rU') as fr:
                data = csv.reader(fr)
                taxonomy, IMT, distribution = data.next()[0:3]
                imls = data.next()
                imls.remove("imls")
                imls_str = " ".join(imls)
                if distribution == 'lognormal':
                    dist = 'LN'
                elif distribution == 'beta':
                    dist = 'BT'
                elif distribution == 'PMF':
                    dist = 'PM'

                nrml_file.write('  <vulnerabilityFunction id="'
                                + taxonomy + '" dist="' + dist + '">\n')
                nrml_file.write('    <imls imt="'+IMT+'">'+imls_str+'</imls>\n')

                if distribution == 'lognormal' or distribution == 'beta':
                    lrs = data.next()
                    lrs.remove("mean")
                    lrs_str = " ".join(lrs)
                    covs = data.next()
                    covs.remove("cov")
                    cov_str = " ".join(covs)
                    nrml_file.write('    <meanLRs>'+lrs_str+'</meanLRs>\n')
                    nrml_file.write('    <covLRs>'+cov_str+'</covLRs>\n')
                elif distribution == 'PMF':
                    data.next()
                    for line in data:
                        lr = line.pop(0)
                        probs = " ".join(line)
                        nrml_file.write('    <probabilities lr="' + lr + '">' + probs + '</probabilities>\n')

                nrml_file.write('  </vulnerabilityFunction>\n\n')

    nrml_file.write('</vulnerabilityModel>\n\n')
    nrml_file.write('</nrml>\n')
    nrml_file.close()

def convert_array_to_string(array):
    string = ''
    for i in range(len(array)):
        string = string + ' ' + str(array[i])

    return string
